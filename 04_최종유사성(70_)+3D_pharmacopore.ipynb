{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8fshkG7-1ok",
        "outputId": "f4197a82-8f85-4efa-c6b1-a00d027693b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3BEJIWe_o45",
        "outputId": "5fdcea7b-a399-41d1-dcde-3ff9038935a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pmapper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG0hHVdw_rBb",
        "outputId": "07b8e0af-cc37-4849-bbe1-899be95c2203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pmapper\n",
            "  Downloading pmapper-1.1.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx>=2 in /usr/local/lib/python3.12/dist-packages (from pmapper) (3.5)\n",
            "Downloading pmapper-1.1.3-py3-none-any.whl (567 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/567.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/567.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.5/567.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pmapper\n",
            "Successfully installed pmapper-1.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "select = pd.read_csv(\"selected_ligands3.smi\", sep='\\t', header=None)\n",
        "select.rename(columns={0: 'smi', 1: 'ID'}, inplace=True)\n",
        "\n",
        "df_smi_id = select[['ID', 'smi']]\n",
        "\n",
        "\n",
        "df_smi_id.to_csv(\"smi_id_only.smi\", index=False)"
      ],
      "metadata": {
        "id": "mkzUL9NmFiYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from tqdm import tqdm\n",
        "from pmapper.pharmacophore import Pharmacophore as P\n",
        "from multiprocessing import Pool, cpu_count\n",
        "\n",
        "# --------------------------------\n",
        "# 1. 입력 및 데이터 정리\n",
        "# --------------------------------\n",
        "# 쉼표(,) 구분자와 'ID', 'smi' 열 이름을 사용합니다.\n",
        "df = pd.read_csv(\"smi_id_only.smi\", sep=\",\", names=['ID','smi'])\n",
        "\n",
        "# TypeError 방지를 위한 데이터 정리 및 타입 변환 (필수)\n",
        "df.dropna(subset=['smi'], inplace=True)\n",
        "df['smi'] = df['smi'].astype(str)\n",
        "\n",
        "# 병렬 처리를 위해 데이터프레임을 리스트로 변환\n",
        "data_to_process = df[['ID', 'smi']].to_dict('records')\n",
        "\n",
        "print(f\"✅ 데이터 준비 완료. 총 {len(data_to_process)}개 분자를 {cpu_count()}개 코어로 처리합니다.\")\n",
        "\n",
        "# --------------------------------\n",
        "# 2. 병렬 처리를 위한 단일 작업 함수 (Worker Function)\n",
        "# --------------------------------\n",
        "def process_molecule(row):\n",
        "    \"\"\"단일 분자에 대해 3D 임베딩 및 Pharmacophore Signature를 계산합니다.\"\"\"\n",
        "    mol_id = row['ID']\n",
        "    smi = row['smi']\n",
        "\n",
        "    # 입력 유효성 검사 및 문자열 변환\n",
        "    smi = str(smi).strip()\n",
        "    if not smi or smi.lower() in ('nan', 'none'):\n",
        "        return mol_id, None\n",
        "\n",
        "    mol = Chem.MolFromSmiles(smi)\n",
        "    if not mol:\n",
        "        return mol_id, None\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "    try:\n",
        "        # 3D 임베딩 (강건성 강화 로직)\n",
        "        AllChem.EmbedMultipleConfs(mol, numConfs=5, maxAttempts=500, pruneRmsThresh=-1, randomSeed=42)\n",
        "        # 생성된 Confomer 중 가장 에너지가 낮은 하나를 선택하여 최적화\n",
        "        AllChem.UFFOptimizeMoleculeConfs(mol)\n",
        "    except:\n",
        "        return mol_id, None # 임베딩 실패\n",
        "\n",
        "    # Pharmacophore signature 생성\n",
        "    try:\n",
        "        p = P()\n",
        "        p.load_from_mol(mol)\n",
        "        sig = p.get_signature_md5(tol=5)\n",
        "        return mol_id, sig\n",
        "    except:\n",
        "        return mol_id, None # Pharmacophore 계산 실패\n",
        "\n",
        "# --------------------------------\n",
        "# 3. 메인 병렬 루프\n",
        "# --------------------------------\n",
        "# CPU 코어 수만큼 프로세스를 생성합니다.\n",
        "num_cores = cpu_count()\n",
        "print(f\"사용 가능한 CPU 코어 수: {num_cores}개\")\n",
        "\n",
        "with Pool(num_cores) as pool:\n",
        "    # pool.imap_unordered를 사용하여 비동기적으로 결과를 얻고 tqdm으로 진행 상태를 표시합니다.\n",
        "    results = list(tqdm(pool.imap_unordered(process_molecule, data_to_process),\n",
        "                        total=len(data_to_process),\n",
        "                        desc=\"Parallel Processing\"))\n",
        "\n",
        "# 결과 처리 (ID를 인덱스로 사용하여 Signature를 매핑)\n",
        "sig_map = {res[0]: res[1] for res in results}\n",
        "df['pharma_sig'] = df['ID'].map(sig_map)\n",
        "\n",
        "# --------------------------------\n",
        "# 4. 저장\n",
        "# --------------------------------\n",
        "df[['ID','smi','pharma_sig']].to_csv(\"pharma_sig_output_parallel.csv\", index=False)\n",
        "print(\"Done! ✅ 병렬 처리로 계산 및 'pharma_sig_output_parallel.csv' 파일로 저장 완료!\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "gKyQbOKw_s6E",
        "outputId": "0083ae4c-4f1a-410c-ad87-150964d0f9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 데이터 준비 완료. 총 30260개 분자를 2개 코어로 처리합니다.\n",
            "사용 가능한 CPU 코어 수: 2개\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[23:59:43] SMILES Parse Error: syntax error while parsing: smi\n",
            "[23:59:43] SMILES Parse Error: check for mistakes around position 2:\n",
            "Parallel Processing:   0%|          | 0/30260 [00:00<?, ?it/s][23:59:43] smi\n",
            "[23:59:43] ~^\n",
            "[23:59:43] SMILES Parse Error: Failed parsing SMILES 'smi' for input: 'smi'\n",
            "Parallel Processing:   0%|          | 13/30260 [00:08<5:43:25,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m                 \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3243506481.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_cores\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;31m# pool.imap_unordered를 사용하여 비동기적으로 결과를 얻고 tqdm으로 진행 상태를 표시합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     results = list(tqdm(pool.imap_unordered(process_molecule, data_to_process), \n\u001b[0m\u001b[1;32m     68\u001b[0m                         \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_process\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                         desc=\"Parallel Processing\"))\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                     \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 설정 및 파일 매핑 확인 ---\n",
        "FP_SCORE_FILE = \"selected_ligands3.smi\"\n",
        "PHARMA_SIG_FILE = \"pharma_sig_output_parallel.csv\"\n",
        "OUTPUT_MERGED_FILE = \"merged_data_for_selection.csv\"\n",
        "\n",
        "# 분석을 통해 확인된 컬럼 이름\n",
        "ID_COLUMN = 'ID'\n",
        "SMILES_COLUMN = 'smi'\n",
        "# 'selected_ligands3.smi'의 4번째 컬럼에 있는 Tanimoto 점수를 사용합니다.\n",
        "SIMILARITY_COLUMN = 'Score_FP_main'\n",
        "\n",
        "# --------------------------------\n",
        "# 1. FP Score 데이터 로드 (selected_ligands3.smi)\n",
        "# --------------------------------\n",
        "# 탭 구분자로 로드하며, 헤더가 없으므로 컬럼 이름을 직접 지정합니다.\n",
        "df_fp = pd.read_csv(\n",
        "    FP_SCORE_FILE, sep='\\t', header=None,\n",
        "    names=[SMILES_COLUMN, ID_COLUMN, 'Mol_Object_Garbage', SIMILARITY_COLUMN, 'Score_2', 'Score_3', 'Score_4']\n",
        ")\n",
        "# FP 점수 컬럼을 실수형(float)으로 변환합니다.\n",
        "df_fp[SIMILARITY_COLUMN] = pd.to_numeric(df_fp[SIMILARITY_COLUMN], errors='coerce')\n",
        "# 최종 병합에 필요한 컬럼만 선택합니다.\n",
        "df_fp = df_fp[[ID_COLUMN, SMILES_COLUMN, SIMILARITY_COLUMN]]\n",
        "\n",
        "\n",
        "# --------------------------------\n",
        "# 2. Pharmacophore Signature 데이터 로드 (pharma_sig_output_parallel.csv)\n",
        "# --------------------------------\n",
        "df_pharma = pd.read_csv(PHARMA_SIG_FILE)\n",
        "# 중복 헤더 행 제거 ('ID' 값이 'ID'인 행)\n",
        "df_pharma_clean = df_pharma[df_pharma[ID_COLUMN] != ID_COLUMN].copy()\n",
        "# 시그니처 값이 없는 (계산 실패) 행은 제거합니다.\n",
        "df_pharma_clean = df_pharma_clean.dropna(subset=['pharma_sig'])\n",
        "\n",
        "\n",
        "# --------------------------------\n",
        "# 3. ID를 기준으로 두 데이터 병합 (sig 추가)\n",
        "# --------------------------------\n",
        "# 두 데이터프레임을 ID를 기준으로 inner join하여 합칩니다.\n",
        "df_final = pd.merge(\n",
        "    df_fp,\n",
        "    df_pharma_clean[[ID_COLUMN, 'pharma_sig']],\n",
        "    on=ID_COLUMN,\n",
        "    how='inner'\n",
        ")\n",
        "df_final.dropna(subset=[SIMILARITY_COLUMN], inplace=True)\n",
        "\n",
        "print(f\"✅ 데이터 병합 완료. 최종 대상 분자 수: {len(df_final)}개\")\n",
        "print(f\"⭐ 병합된 데이터가 '{OUTPUT_MERGED_FILE}' 파일로 저장되었습니다.\")\n",
        "df_final.to_csv(OUTPUT_MERGED_FILE, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTq_eRTmTmeh",
        "outputId": "b0b222de-9c0c-4c84-8188-26154d08c52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 데이터 병합 완료. 최종 대상 분자 수: 28574개\n",
            "⭐ 병합된 데이터가 'merged_data_for_selection.csv' 파일로 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# --- 설정 및 파일 매핑 확인 ---\n",
        "FP_SCORE_FILE = \"selected_ligands3.smi\"\n",
        "PHARMA_SIG_FILE = \"pharma_sig_output_parallel.csv\"\n",
        "# ⭐ 최종 파일명을 .smi로 지정\n",
        "OUTPUT_MERGED_FILE = \"merged_data_for_selection_smi_id.smi\"\n",
        "DELIMITER = '\\t' # 탭 구분자\n",
        "\n",
        "# 분석을 통해 확인된 컬럼 이름\n",
        "ID_COLUMN = 'ID'\n",
        "SMILES_COLUMN = 'smi'\n",
        "SIMILARITY_COLUMN = 'Score_FP_main'\n",
        "\n",
        "# --------------------------------\n",
        "# 1. FP Score 데이터 로드 및 정리 (selected_ligands3.smi)\n",
        "# --------------------------------\n",
        "df_fp = pd.read_csv(\n",
        "    FP_SCORE_FILE, sep=DELIMITER, header=None,\n",
        "    names=[SMILES_COLUMN, ID_COLUMN, 'Mol_Object_Garbage', SIMILARITY_COLUMN, 'Score_2', 'Score_3', 'Score_4']\n",
        ")\n",
        "df_fp[SIMILARITY_COLUMN] = pd.to_numeric(df_fp[SIMILARITY_COLUMN], errors='coerce')\n",
        "df_fp = df_fp[[ID_COLUMN, SMILES_COLUMN, SIMILARITY_COLUMN, 'Score_2', 'Score_3', 'Score_4']]\n",
        "\n",
        "\n",
        "# --------------------------------\n",
        "# 2. Pharmacophore Signature 데이터 로드 및 정리\n",
        "# --------------------------------\n",
        "df_pharma = pd.read_csv(PHARMA_SIG_FILE)\n",
        "df_pharma_clean = df_pharma[df_pharma[ID_COLUMN] != ID_COLUMN].copy()\n",
        "df_pharma_clean = df_pharma_clean.dropna(subset=['pharma_sig'])\n",
        "\n",
        "\n",
        "# --------------------------------\n",
        "# 3. ID를 기준으로 두 데이터 병합 및 컬럼 순서 조정\n",
        "# --------------------------------\n",
        "df_final = pd.merge(\n",
        "    df_fp,\n",
        "    df_pharma_clean[[ID_COLUMN, 'pharma_sig']],\n",
        "    on=ID_COLUMN,\n",
        "    how='inner'\n",
        ")\n",
        "df_final.dropna(subset=[SIMILARITY_COLUMN], inplace=True)\n",
        "\n",
        "# ⭐ 핵심: 컬럼 순서를 [smi, ID, ...]로 변경\n",
        "# 나머지 컬럼들은 순서대로 뒤에 붙습니다.\n",
        "ordered_cols = [SMILES_COLUMN, ID_COLUMN] + [col for col in df_final.columns if col not in [SMILES_COLUMN, ID_COLUMN]]\n",
        "df_final = df_final[ordered_cols]\n",
        "\n",
        "print(f\"✅ 데이터 병합 완료. 최종 대상 분자 수: {len(df_final)}개\")\n",
        "\n",
        "# 탭 구분자로 파일 저장\n",
        "df_final.to_csv(OUTPUT_MERGED_FILE, sep=DELIMITER, index=False, header=True)\n",
        "print(f\"⭐ 탭 구분자로 '{OUTPUT_MERGED_FILE}' 파일에 smi, ID 형태로 저장 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8xFVW5cXcad",
        "outputId": "7e3e6ae2-c72d-426b-f7a0-1b80791e6d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 데이터 병합 완료. 최종 대상 분자 수: 28574개\n",
            "⭐ 탭 구분자로 'merged_data_for_selection_smi_id.smi' 파일에 smi, ID 형태로 저장 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------\n",
        "# 4. FP 점수 (Score_FP_main)로 상위 70% (7,000개) 추출\n",
        "# --------------------------------\n",
        "TARGET_COUNT = 7060\n",
        "OUTPUT_7K_FILE = \"top_7000_similarity_selection_smi_id.smi\"\n",
        "\n",
        "# FP 점수(Score_FP_main)를 기준으로 내림차순 정렬\n",
        "df_sorted = df_final.sort_values(by=SIMILARITY_COLUMN, ascending=False)\n",
        "\n",
        "# 상위 7,000개 분자 선택\n",
        "df_top_7k = df_sorted.head(TARGET_COUNT)\n",
        "\n",
        "# 탭 구분자로 파일 저장 (SMI ID 형태 유지)\n",
        "df_top_7k.to_csv(OUTPUT_7K_FILE, sep=DELIMITER, index=False, header=True)\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(f\"✅ FP 유사성 기준 상위 {len(df_top_7k)}개 후보가 '{OUTPUT_7K_FILE}' 파일에 저장 완료!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynrdk_HTXqmV",
        "outputId": "407893aa-4933-4ac4-f977-2ea7b47c55bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "✅ FP 유사성 기준 상위 7060개 후보가 'top_7000_similarity_selection_smi_id.smi' 파일에 저장 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------\n",
        "# 3. FP 점수 (Score_FP_main)로 상위 70% (7,000개) 추출\n",
        "# --------------------------------\n",
        "TARGET_COUNT = 7060\n",
        "OUTPUT_7K_FILE = \"top_7000_similarity_selection_smi_id_only.smi\"\n",
        "\n",
        "# FP 점수(Score_FP_main)를 기준으로 내림차순 정렬\n",
        "df_sorted = df_final.sort_values(by=SIMILARITY_COLUMN, ascending=False)\n",
        "\n",
        "# 상위 7,000개 분자 선택\n",
        "df_top_7k = df_sorted.head(TARGET_COUNT)\n",
        "\n",
        "# ⭐ SMI ID 만 파일로 저장 (헤더 없이)\n",
        "df_top_7k[[SMILES_COLUMN, ID_COLUMN]].to_csv(OUTPUT_7K_FILE, sep=DELIMITER, index=False, header=False)\n",
        "\n",
        "print(\"-\" * 30)\n",
        "print(f\"✅ FP 유사성 기준 상위 {len(df_top_7k)}개 후보가 SMI ID 형태로 '{OUTPUT_7K_FILE}' 파일에 저장 완료!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXNAjHDXXzF9",
        "outputId": "94e04ab6-f4e3-4021-edea-9890de047a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "✅ FP 유사성 기준 상위 7060개 후보가 SMI ID 형태로 'top_7000_similarity_selection_smi_id_only.smi' 파일에 저장 완료!\n"
          ]
        }
      ]
    }
  ]
}